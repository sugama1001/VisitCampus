{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7101861,
          "sourceType": "datasetVersion",
          "datasetId": 4093957
        },
        {
          "sourceId": 7105764,
          "sourceType": "datasetVersion",
          "datasetId": 4096532
        },
        {
          "sourceId": 2568,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 1879
        },
        {
          "sourceId": 2588,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 1884
        },
        {
          "sourceId": 3123,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 2334
        }
      ],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OoWn6mOsww5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cacda32-f6e4-4dff-e2b9-07a0191f895e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_hub\n",
        "!pip install -q -U \"tensorflow-text==2.13.*\"\n",
        "!pip install \"tf-models-official==2.13.*\""
      ],
      "metadata": {
        "id": "zZNQCvgpnIg_",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:10:49.180398Z",
          "iopub.execute_input": "2023-12-03T03:10:49.181364Z",
          "iopub.status.idle": "2023-12-03T03:11:37.304291Z",
          "shell.execute_reply.started": "2023-12-03T03:10:49.181325Z",
          "shell.execute_reply": "2023-12-03T03:11:37.303068Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb37dcb-1bab-4e95-a284-340f4a889499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-models-official==2.13.*\n",
            "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.0.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official==2.13.*)\n",
            "  Downloading immutabledict-4.0.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.8.1.78)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official==2.13.*)\n",
            "  Downloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.11.4)\n",
            "Collecting sentencepiece (from tf-models-official==2.13.*)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official==2.13.*)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.13.*)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-text~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.59.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.13.*) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.42.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=51c6fb4e7e2a77284cf0a154c3a220c22e7353156f8d3de3e48c89b0125ace84\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, tensorflow-model-optimization, portalocker, immutabledict, colorama, sacrebleu, seqeval, tf-models-official\n",
            "Successfully installed colorama-0.4.6 immutabledict-4.0.0 portalocker-2.8.2 sacrebleu-2.3.3 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-model-optimization-0.7.5 tf-models-official-2.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "from official.nlp import optimization\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r3NYUQhXpW-a",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.307065Z",
          "iopub.execute_input": "2023-12-03T03:11:37.307941Z",
          "iopub.status.idle": "2023-12-03T03:11:37.313044Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.307900Z",
          "shell.execute_reply": "2023-12-03T03:11:37.312085Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/dataset_sn.csv\")\n",
        "dataset = dataset.drop('type', axis=1)\n",
        "\n",
        "# Cetak dataset pelatihan\n",
        "print(\"List Dataset:\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "w_PZsO08Ih56",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.314084Z",
          "iopub.execute_input": "2023-12-03T03:11:37.314361Z",
          "iopub.status.idle": "2023-12-03T03:11:37.340377Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.314336Z",
          "shell.execute_reply": "2023-12-03T03:11:37.339472Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339acea1-e5b9-4ff7-c2e1-fb4bd53f6de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List Dataset:\n",
            "    label                                                 SN\n",
            "0       S  Saya menyukai hal-hal yang konkret dan praktis...\n",
            "1       S  Saya lebih memilih berfokus pada fakta dan log...\n",
            "2       S  Saya menghargai kejujuran dan konsistensi, dan...\n",
            "3       S  Saya lebih nyaman ketika memiliki jadwal yang ...\n",
            "4       S  Saya suka mengamati hal-hal yang ada di sekita...\n",
            "..    ...                                                ...\n",
            "395     N  Saya lebih terbuka terhadap konsep abstrak, se...\n",
            "396     N  Saya merasa terkoneksi dengan ide-ide yang bel...\n",
            "397     N  Keputusan saya cenderung dipengaruhi oleh intu...\n",
            "398     N  Tanpa perlu dipandu oleh petunjuk yang rinci, ...\n",
            "399     N  Kesanggupannya untuk membaca ekspresi wajah da...\n",
            "\n",
            "[400 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "df['SN'] = df['SN'].str.strip()\n",
        "\n",
        "# Membagi dataset berdasarkan kelompok\n",
        "grouped = df.groupby('label')\n",
        "\n",
        "# Inisialisasi DataFrame train dan valid\n",
        "df_train = pd.DataFrame()\n",
        "df_valid = pd.DataFrame()\n",
        "\n",
        "# Memproses setiap kelompok\n",
        "for name, group in grouped:\n",
        "    # Menentukan jumlah data untuk validasi\n",
        "    valid_size = int(len(group) * 0.2)\n",
        "\n",
        "    # Memilih data untuk validasi\n",
        "    valid_data = group.sample(n=valid_size, random_state=42)\n",
        "\n",
        "    # Memilih data untuk train\n",
        "    train_data = group.drop(valid_data.index)\n",
        "\n",
        "    # Menggabungkan hasil pemisahan ke dalam DataFrame train dan valid\n",
        "    df_train = pd.concat([df_train, train_data])\n",
        "    df_valid = pd.concat([df_valid, valid_data])\n",
        "\n",
        "#acak\n",
        "df_train = df_train.sample(frac=1, random_state=42)\n",
        "df_valid= df_valid.sample(frac=1, random_state=42)\n",
        "\n",
        "# Cetak hasil\n",
        "# print(\"Data Train:\")\n",
        "# print(df_train)\n",
        "# print(\"\\nData Valid:\")\n",
        "# print(df_valid)"
      ],
      "metadata": {
        "id": "gWKDzwo0-l3K",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.341671Z",
          "iopub.execute_input": "2023-12-03T03:11:37.342028Z",
          "iopub.status.idle": "2023-12-03T03:11:37.358388Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.341994Z",
          "shell.execute_reply": "2023-12-03T03:11:37.357444Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df_train\n",
        "valid_data = df_valid\n",
        "target_label = 'S' #label 1 Ekstrovert #label 1 Sensing #label 1 feeling #label 1 perceiving\n",
        "label_train = (train_data['label'].str[0] == target_label).astype(int).to_numpy()\n",
        "label_valid = (valid_data['label'].str[0] == target_label).astype(int).to_numpy()"
      ],
      "metadata": {
        "id": "7t3QgeEnXEV9",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.360797Z",
          "iopub.execute_input": "2023-12-03T03:11:37.361080Z",
          "iopub.status.idle": "2023-12-03T03:11:37.374176Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.361054Z",
          "shell.execute_reply": "2023-12-03T03:11:37.373330Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data['SN'].to_numpy() #isi sesuai kolom dataset\n",
        "x_valid = valid_data['SN'].to_numpy()\n",
        "# print(x_train.shape,x_valid.shape)\n",
        "# # print(label_train)\n",
        "# # print(x_train)"
      ],
      "metadata": {
        "id": "diK2gNqhbPAH",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.375298Z",
          "iopub.execute_input": "2023-12-03T03:11:37.375563Z",
          "iopub.status.idle": "2023-12-03T03:11:37.384101Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.375538Z",
          "shell.execute_reply": "2023-12-03T03:11:37.383278Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_url = 'https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-l-12-h-768-a-12/versions/4'\n",
        "preprocess_url = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-preprocess/versions/3\"\n",
        "embedding_model1 = hub.KerasLayer(encoder_url, trainable=True)\n",
        "preprocess_model1 = hub.KerasLayer(preprocess_url)"
      ],
      "metadata": {
        "id": "myuT0XKfqIT1",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:37.385210Z",
          "iopub.execute_input": "2023-12-03T03:11:37.385496Z",
          "iopub.status.idle": "2023-12-03T03:11:50.221860Z",
          "shell.execute_reply.started": "2023-12-03T03:11:37.385461Z",
          "shell.execute_reply": "2023-12-03T03:11:50.221037Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.utils.register_keras_serializable(package='Custom', name='KerasLayer')\n",
        "class KerasLayerWrapper(hub.KerasLayer):\n",
        "    pass\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input1           = tf.keras.layers.Input(shape=(), dtype=tf.string, name='Input_Sensing-Intuitive')\n",
        "    preprocessing_layer1  = KerasLayerWrapper(preprocess_model1, name='Bert_Preprocessing-Sensing_Intuitive')\n",
        "    encoder_inputs1       = preprocessing_layer1(text_input1)\n",
        "    encoder1              = KerasLayerWrapper(embedding_model1, name='Bert-Encoder_Sensing-Intuitive',trainable=True)\n",
        "    outputs1              = encoder1(encoder_inputs1)['pooled_output']\n",
        "    outputs1              = tf.keras.layers.Dropout(0.5 , name=\"Dropout_Sensing-Intuitive\")(outputs1)\n",
        "    outputs1              = tf.keras.layers.Flatten(name = \"Flatten-Sensing-Intuitive\")(outputs1)\n",
        "    outputs1              = tf.keras.layers.Reshape((1, -1), name = \"Reshape-Sensing_Intuitive\")(outputs1)\n",
        "    outputs1              = tf.keras.layers.LSTM(64, return_sequences=True, name = \"LSTM-1_Sensing-Intuitive\")(outputs1)\n",
        "    outputs1              = tf.keras.layers.LSTM(64, name = \"LSTM-2_Sensing_Intuitive\")(outputs1)\n",
        "    outputs1              = tf.keras.layers.Dense(512, activation='relu', name = \"Dense_1-Sensing_Intuitive\")(outputs1)\n",
        "    label1                = tf.keras.layers.Dense(1, activation='sigmoid', name='Classifier_Sensing-Intuitive')(outputs1)\n",
        "\n",
        "    return tf.keras.Model(inputs=[text_input1], outputs=[label1])"
      ],
      "metadata": {
        "id": "_Vh5uPDtDL5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_classifier_model():\n",
        "#     text_input1 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text1')\n",
        "\n",
        "#     # Gunakan lapisan pre-processing terpisah untuk setiap input\n",
        "#     preprocessing_layer1 = hub.KerasLayer(preprocess_model1, name='preprocessing1')\n",
        "#     encoder_inputs1 = preprocessing_layer1(text_input1)\n",
        "#     encoder1 = hub.KerasLayer(embedding_model1, name='BERT_encoder_1', trainable=True)\n",
        "#     outputs1 = encoder1(encoder_inputs1)['pooled_output']\n",
        "#     outputs1 = tf.keras.layers.Dropout(0.5 , name=\"dropout_1\")(outputs1)\n",
        "#     outputs1 = tf.keras.layers.Flatten()(outputs1)\n",
        "#     outputs1 = tf.keras.layers.Reshape((1, -1))(outputs1)\n",
        "#     outputs1 = tf.keras.layers.LSTM(64, return_sequences=True)(outputs1)\n",
        "#     outputs1 = tf.keras.layers.LSTM(64)(outputs1)\n",
        "#     outputs1 = tf.keras.layers.Dense(512, activation='relu')(outputs1)\n",
        "#     label1 = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier1')(outputs1)\n",
        "\n",
        "#     return tf.keras.Model(inputs=[text_input1], outputs=[label1])\n"
      ],
      "metadata": {
        "id": "nVp2ZiKWJApS",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:50.223102Z",
          "iopub.execute_input": "2023-12-03T03:11:50.223416Z",
          "iopub.status.idle": "2023-12-03T03:11:50.230159Z",
          "shell.execute_reply.started": "2023-12-03T03:11:50.223387Z",
          "shell.execute_reply": "2023-12-03T03:11:50.229240Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_classifier_model()\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "kAUGnHx7NfbL",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:50.231281Z",
          "iopub.execute_input": "2023-12-03T03:11:50.231544Z",
          "iopub.status.idle": "2023-12-03T03:11:50.606465Z",
          "shell.execute_reply.started": "2023-12-03T03:11:50.231520Z",
          "shell.execute_reply": "2023-12-03T03:11:50.605603Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/sensing_intuitive_weights.h5\")"
      ],
      "metadata": {
        "id": "hFnSiPVIQ2yS",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:50.607822Z",
          "iopub.execute_input": "2023-12-03T03:11:50.608182Z",
          "iopub.status.idle": "2023-12-03T03:11:50.660396Z",
          "shell.execute_reply.started": "2023-12-03T03:11:50.608147Z",
          "shell.execute_reply": "2023-12-03T03:11:50.659455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/model_sensing_intuitive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rYd_mbBBQ1X",
        "outputId": "b9d352e2-dcf7-4c49-9709-6140bbfe1739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:`Input_Sensing-Intuitive` is not a valid tf.function parameter name. Sanitizing to `Input_Sensing_Intuitive`.\n",
            "WARNING:absl:`Input_Sensing-Intuitive` is not a valid tf.function parameter name. Sanitizing to `Input_Sensing_Intuitive`.\n",
            "WARNING:absl:`Input_Sensing-Intuitive` is not a valid tf.function parameter name. Sanitizing to `Input_Sensing_Intuitive`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "steps_per_epoch = 16\n",
        "batch_size = 2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001)"
      ],
      "metadata": {
        "id": "_6mdEf0wR51q",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:50.661661Z",
          "iopub.execute_input": "2023-12-03T03:11:50.661958Z",
          "iopub.status.idle": "2023-12-03T03:11:50.668682Z",
          "shell.execute_reply.started": "2023-12-03T03:11:50.661932Z",
          "shell.execute_reply": "2023-12-03T03:11:50.667779Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q tf-models-official"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-03T03:11:50.669880Z",
          "iopub.execute_input": "2023-12-03T03:11:50.670400Z",
          "iopub.status.idle": "2023-12-03T03:12:03.411458Z",
          "shell.execute_reply.started": "2023-12-03T03:11:50.670373Z",
          "shell.execute_reply": "2023-12-03T03:12:03.410117Z"
        },
        "trusted": true,
        "id": "QdTh1nK-wpjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),  # Fungsi kerugian untuk klasifikasi biner\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UjIESrHJSGVh",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:12:03.413287Z",
          "iopub.execute_input": "2023-12-03T03:12:03.413699Z",
          "iopub.status.idle": "2023-12-03T03:12:03.430809Z",
          "shell.execute_reply.started": "2023-12-03T03:12:03.413659Z",
          "shell.execute_reply": "2023-12-03T03:12:03.429844Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs['loss'] <= 0.1 and logs['val_loss'] <= 0.1:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Path untuk menyimpan checkpoint pada setiap epoch\n",
        "checkpoint_path_epoch = \"/content/model/model_checkpoint_epoch.h5\"\n",
        "\n",
        "# Path untuk menyimpan checkpoint model terbaik\n",
        "checkpoint_path_best = \"/content/model/model_checkpoint_best.h5\"\n",
        "\n",
        "# Callback untuk menyimpan checkpoint pada setiap epoch\n",
        "checkpoint_callback_epoch = ModelCheckpoint(\n",
        "    filepath=checkpoint_path_epoch,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False,  # Set ke False agar menyimpan pada setiap epoch\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Callback untuk menyimpan checkpoint model terbaik\n",
        "checkpoint_callback_best = ModelCheckpoint(\n",
        "    filepath=checkpoint_path_best,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,  # Set ke True agar hanya menyimpan model terbaik\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "JXgAHcGsBAF1",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:12:03.435524Z",
          "iopub.execute_input": "2023-12-03T03:12:03.435791Z",
          "iopub.status.idle": "2023-12-03T03:12:03.441933Z",
          "shell.execute_reply.started": "2023-12-03T03:12:03.435768Z",
          "shell.execute_reply": "2023-12-03T03:12:03.440987Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# untuk lanjut\n",
        "model.fit(\n",
        "    x=x_train, y=label_train,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_valid, label_valid),batch_size=batch_size,\n",
        "    callbacks=[checkpoint_callback_epoch,checkpoint_callback_best, CustomCallback()]\n",
        ")"
      ],
      "metadata": {
        "id": "czR2DhK1nuDl",
        "outputId": "4993bce7-ceae-4238-a784-30fb2f07c43b",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:12:03.443200Z",
          "iopub.execute_input": "2023-12-03T03:12:03.443570Z",
          "iopub.status.idle": "2023-12-03T03:17:33.279126Z",
          "shell.execute_reply.started": "2023-12-03T03:12:03.443533Z",
          "shell.execute_reply": "2023-12-03T03:17:33.278114Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5375\n",
            "Epoch 1: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.69285, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 167ms/step - loss: 0.6928 - accuracy: 0.5375 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5469\n",
            "Epoch 2: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.69285 to 0.69252, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 183ms/step - loss: 0.6927 - accuracy: 0.5469 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5437\n",
            "Epoch 3: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.69252 to 0.69202, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 34s 210ms/step - loss: 0.6925 - accuracy: 0.5437 - val_loss: 0.6920 - val_accuracy: 0.5250\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.6281\n",
            "Epoch 4: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.69202 to 0.69005, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 30s 187ms/step - loss: 0.6917 - accuracy: 0.6281 - val_loss: 0.6900 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.6781\n",
            "Epoch 5: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.69005 to 0.68733, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 176ms/step - loss: 0.6899 - accuracy: 0.6781 - val_loss: 0.6873 - val_accuracy: 0.7250\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.7344\n",
            "Epoch 6: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.68733 to 0.68307, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 176ms/step - loss: 0.6873 - accuracy: 0.7344 - val_loss: 0.6831 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.7937\n",
            "Epoch 7: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.68307 to 0.67640, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 25s 158ms/step - loss: 0.6825 - accuracy: 0.7937 - val_loss: 0.6764 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.8438\n",
            "Epoch 8: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.67640 to 0.66901, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.6768 - accuracy: 0.8438 - val_loss: 0.6690 - val_accuracy: 0.8375\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6693 - accuracy: 0.8875\n",
            "Epoch 9: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.66901 to 0.66151, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 184ms/step - loss: 0.6693 - accuracy: 0.8875 - val_loss: 0.6615 - val_accuracy: 0.8500\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.8938\n",
            "Epoch 10: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.66151 to 0.65086, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 177ms/step - loss: 0.6603 - accuracy: 0.8938 - val_loss: 0.6509 - val_accuracy: 0.9000\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.9156\n",
            "Epoch 11: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.65086 to 0.64584, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 32s 198ms/step - loss: 0.6499 - accuracy: 0.9156 - val_loss: 0.6458 - val_accuracy: 0.8625\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.9344\n",
            "Epoch 12: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.64584\n",
            "160/160 [==============================] - 20s 126ms/step - loss: 0.6401 - accuracy: 0.9344 - val_loss: 0.6505 - val_accuracy: 0.7875\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.9594\n",
            "Epoch 13: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.64584 to 0.62135, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 173ms/step - loss: 0.6278 - accuracy: 0.9594 - val_loss: 0.6214 - val_accuracy: 0.9250\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.9594\n",
            "Epoch 14: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.62135 to 0.61735, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.6169 - accuracy: 0.9594 - val_loss: 0.6173 - val_accuracy: 0.8875\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.9781\n",
            "Epoch 15: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.61735 to 0.60317, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 170ms/step - loss: 0.6059 - accuracy: 0.9781 - val_loss: 0.6032 - val_accuracy: 0.9000\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.9844\n",
            "Epoch 16: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.60317 to 0.59277, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 31s 192ms/step - loss: 0.5918 - accuracy: 0.9844 - val_loss: 0.5928 - val_accuracy: 0.9250\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.9750\n",
            "Epoch 17: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.59277 to 0.58219, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 184ms/step - loss: 0.5837 - accuracy: 0.9750 - val_loss: 0.5822 - val_accuracy: 0.9250\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.9812\n",
            "Epoch 18: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.58219\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.5726 - accuracy: 0.9812 - val_loss: 0.5853 - val_accuracy: 0.8875\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.9812\n",
            "Epoch 19: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.58219 to 0.56566, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 33s 206ms/step - loss: 0.5642 - accuracy: 0.9812 - val_loss: 0.5657 - val_accuracy: 0.9250\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.9875\n",
            "Epoch 20: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.56566 to 0.55151, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.5518 - accuracy: 0.9875 - val_loss: 0.5515 - val_accuracy: 0.9375\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.9875\n",
            "Epoch 21: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.55151 to 0.54657, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 172ms/step - loss: 0.5414 - accuracy: 0.9875 - val_loss: 0.5466 - val_accuracy: 0.9250\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.9875\n",
            "Epoch 22: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.54657 to 0.53413, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 172ms/step - loss: 0.5316 - accuracy: 0.9875 - val_loss: 0.5341 - val_accuracy: 0.9375\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.9875\n",
            "Epoch 23: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.53413 to 0.53248, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 167ms/step - loss: 0.5221 - accuracy: 0.9875 - val_loss: 0.5325 - val_accuracy: 0.9125\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.9812\n",
            "Epoch 24: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.53248 to 0.53059, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 182ms/step - loss: 0.5150 - accuracy: 0.9812 - val_loss: 0.5306 - val_accuracy: 0.8875\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.9844\n",
            "Epoch 25: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.53059\n",
            "160/160 [==============================] - 22s 141ms/step - loss: 0.5053 - accuracy: 0.9844 - val_loss: 0.5334 - val_accuracy: 0.8875\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.9937\n",
            "Epoch 26: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.53059 to 0.50393, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 178ms/step - loss: 0.4914 - accuracy: 0.9937 - val_loss: 0.5039 - val_accuracy: 0.9250\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.9875\n",
            "Epoch 27: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.50393 to 0.50374, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 184ms/step - loss: 0.4850 - accuracy: 0.9875 - val_loss: 0.5037 - val_accuracy: 0.9125\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.9844\n",
            "Epoch 28: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.50374\n",
            "160/160 [==============================] - 20s 124ms/step - loss: 0.4782 - accuracy: 0.9844 - val_loss: 0.5039 - val_accuracy: 0.9000\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.9688\n",
            "Epoch 29: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.50374 to 0.48435, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.4760 - accuracy: 0.9688 - val_loss: 0.4844 - val_accuracy: 0.9250\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.9906\n",
            "Epoch 30: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.48435 to 0.47124, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 30s 187ms/step - loss: 0.4563 - accuracy: 0.9906 - val_loss: 0.4712 - val_accuracy: 0.9375\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.9812\n",
            "Epoch 31: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.47124 to 0.45875, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 33s 205ms/step - loss: 0.4512 - accuracy: 0.9812 - val_loss: 0.4588 - val_accuracy: 0.9375\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.9937\n",
            "Epoch 32: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.45875 to 0.45257, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.4364 - accuracy: 0.9937 - val_loss: 0.4526 - val_accuracy: 0.9375\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.9969\n",
            "Epoch 33: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.45257 to 0.44528, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 32s 201ms/step - loss: 0.4254 - accuracy: 0.9969 - val_loss: 0.4453 - val_accuracy: 0.9375\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.9875\n",
            "Epoch 34: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.44528\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4234 - accuracy: 0.9875 - val_loss: 0.6203 - val_accuracy: 0.6875\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.9875\n",
            "Epoch 35: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.44528 to 0.43263, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.4143 - accuracy: 0.9875 - val_loss: 0.4326 - val_accuracy: 0.9375\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.9969\n",
            "Epoch 36: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.43263 to 0.42522, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 167ms/step - loss: 0.3993 - accuracy: 0.9969 - val_loss: 0.4252 - val_accuracy: 0.9375\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.9969\n",
            "Epoch 37: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.42522\n",
            "160/160 [==============================] - 20s 126ms/step - loss: 0.3906 - accuracy: 0.9969 - val_loss: 0.4287 - val_accuracy: 0.9250\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.9969\n",
            "Epoch 38: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 38: val_loss improved from 0.42522 to 0.41875, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 172ms/step - loss: 0.3832 - accuracy: 0.9969 - val_loss: 0.4187 - val_accuracy: 0.9250\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 1.0000\n",
            "Epoch 39: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 39: val_loss improved from 0.41875 to 0.40928, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 30s 187ms/step - loss: 0.3708 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9375\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 1.0000\n",
            "Epoch 40: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.40928 to 0.40164, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 165ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9375\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 1.0000\n",
            "Epoch 41: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 41: val_loss improved from 0.40164 to 0.39419, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 179ms/step - loss: 0.3537 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9375\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.9969\n",
            "Epoch 42: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.39419\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.3487 - accuracy: 0.9969 - val_loss: 0.4211 - val_accuracy: 0.9000\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.9750\n",
            "Epoch 43: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.39419 to 0.38033, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 180ms/step - loss: 0.3545 - accuracy: 0.9750 - val_loss: 0.3803 - val_accuracy: 0.9375\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 1.0000\n",
            "Epoch 44: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.38033 to 0.37466, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 25s 158ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9375\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.9906\n",
            "Epoch 45: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.37466\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.3296 - accuracy: 0.9906 - val_loss: 0.3874 - val_accuracy: 0.9125\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 1.0000\n",
            "Epoch 46: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.37466\n",
            "160/160 [==============================] - 20s 126ms/step - loss: 0.3133 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9125\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.9937\n",
            "Epoch 47: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.37466\n",
            "160/160 [==============================] - 20s 126ms/step - loss: 0.3120 - accuracy: 0.9937 - val_loss: 0.3944 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.9969\n",
            "Epoch 48: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 48: val_loss improved from 0.37466 to 0.36734, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 30s 190ms/step - loss: 0.3017 - accuracy: 0.9969 - val_loss: 0.3673 - val_accuracy: 0.9250\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 1.0000\n",
            "Epoch 49: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.36734\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.2910 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9125\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 1.0000\n",
            "Epoch 50: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 50: val_loss improved from 0.36734 to 0.36733, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.2837 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9125\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.9969\n",
            "Epoch 51: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.36733 to 0.35160, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 185ms/step - loss: 0.2803 - accuracy: 0.9969 - val_loss: 0.3516 - val_accuracy: 0.9125\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 1.0000\n",
            "Epoch 52: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.35160 to 0.34294, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.2699 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9250\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 1.0000\n",
            "Epoch 53: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 53: val_loss improved from 0.34294 to 0.33918, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 33s 205ms/step - loss: 0.2625 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9250\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 1.0000\n",
            "Epoch 54: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 54: val_loss improved from 0.33918 to 0.33341, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 180ms/step - loss: 0.2562 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9375\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 1.0000\n",
            "Epoch 55: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 55: val_loss improved from 0.33341 to 0.32552, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 27s 166ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9375\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 1.0000\n",
            "Epoch 56: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 56: val_loss improved from 0.32552 to 0.32076, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 178ms/step - loss: 0.2419 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9375\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 1.0000\n",
            "Epoch 57: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 57: val_loss improved from 0.32076 to 0.31742, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 174ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9375\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 1.0000\n",
            "Epoch 58: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 58: val_loss improved from 0.31742 to 0.31674, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 34s 210ms/step - loss: 0.2296 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9250\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 1.0000\n",
            "Epoch 59: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 59: val_loss improved from 0.31674 to 0.31465, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 33s 206ms/step - loss: 0.2236 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9250\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 1.0000\n",
            "Epoch 60: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 60: val_loss improved from 0.31465 to 0.31276, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9250\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 1.0000\n",
            "Epoch 61: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 61: val_loss improved from 0.31276 to 0.30847, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 179ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9250\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 1.0000\n",
            "Epoch 62: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.30847\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.2051 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9125\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 1.0000\n",
            "Epoch 63: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 63: val_loss improved from 0.30847 to 0.30505, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 172ms/step - loss: 0.1992 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9125\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 1.0000\n",
            "Epoch 64: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 64: val_loss improved from 0.30505 to 0.29669, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 173ms/step - loss: 0.1939 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9250\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 1.0000\n",
            "Epoch 65: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.29669\n",
            "160/160 [==============================] - 22s 139ms/step - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9250\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 1.0000\n",
            "Epoch 66: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.29669\n",
            "160/160 [==============================] - 20s 126ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9125\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 1.0000\n",
            "Epoch 67: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 67: val_loss improved from 0.29669 to 0.29219, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 173ms/step - loss: 0.1775 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9250\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 1.0000\n",
            "Epoch 68: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 68: val_loss improved from 0.29219 to 0.28728, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.1722 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9250\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 1.0000\n",
            "Epoch 69: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 69: val_loss improved from 0.28728 to 0.27864, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 35s 216ms/step - loss: 0.1672 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9250\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 1.0000\n",
            "Epoch 70: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 70: val_loss improved from 0.27864 to 0.27828, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1621 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9250\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 1.0000\n",
            "Epoch 71: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 71: val_loss improved from 0.27828 to 0.27510, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.1570 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9250\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 1.0000\n",
            "Epoch 72: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 72: val_loss improved from 0.27510 to 0.27126, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 176ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9250\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 1.0000\n",
            "Epoch 73: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 73: val_loss improved from 0.27126 to 0.26522, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9375\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 1.0000\n",
            "Epoch 74: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 74: val_loss improved from 0.26522 to 0.25720, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 177ms/step - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9375\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000\n",
            "Epoch 75: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 75: val_loss improved from 0.25720 to 0.25560, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 30s 187ms/step - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9375\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 1.0000\n",
            "Epoch 76: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 76: val_loss improved from 0.25560 to 0.25350, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 28s 172ms/step - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9375\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 1.0000\n",
            "Epoch 77: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.25350\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.1299 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9375\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 1.0000\n",
            "Epoch 78: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.25350\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9375\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 1.0000\n",
            "Epoch 79: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 79: val_loss improved from 0.25350 to 0.25268, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 29s 180ms/step - loss: 0.1215 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9375\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 1.0000\n",
            "Epoch 80: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.25268\n",
            "160/160 [==============================] - 23s 146ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9375\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 1.0000\n",
            "Epoch 81: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 81: val_loss improved from 0.25268 to 0.25069, saving model to /content/model/model_checkpoint_best.h5\n",
            "160/160 [==============================] - 26s 165ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9375\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 1.0000\n",
            "Epoch 82: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9125\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 1.0000\n",
            "Epoch 83: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9250\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9969\n",
            "Epoch 84: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.1098 - accuracy: 0.9969 - val_loss: 0.2693 - val_accuracy: 0.9250\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9969\n",
            "Epoch 85: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.1066 - accuracy: 0.9969 - val_loss: 0.3513 - val_accuracy: 0.8875\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000\n",
            "Epoch 86: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9125\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000\n",
            "Epoch 87: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9125\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 1.0000\n",
            "Epoch 88: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 36s 223ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9125\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 89: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9125\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 90: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9125\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000\n",
            "Epoch 91: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9125\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 92: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9125\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 1.0000\n",
            "Epoch 93: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9125\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 1.0000\n",
            "Epoch 94: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9125\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 1.0000\n",
            "Epoch 95: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9125\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 96: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9125\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 97: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 28s 176ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9125\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 1.0000\n",
            "Epoch 98: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9125\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 1.0000\n",
            "Epoch 99: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 23s 145ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9125\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 100: saving model to /content/model/model_checkpoint_epoch.h5\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.25069\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d80abeab730>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/sensing_intuitive_weights.h5\")"
      ],
      "metadata": {
        "id": "UNblYWkvCcJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/model_sn/\")"
      ],
      "metadata": {
        "id": "DGrraiwfPDRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sensing == 1\n",
        "model.predict([\"senang menyimak keadaan sekitarnya dengan seksama. Setiap hari, ia akan memperhatikan hal-hal kecil yang mungkin terlewatkan oleh orang lain. Misalnya, ia selalu tahu kapan tetangganya mengganti bunga di halaman depan rumahnya atau ketika ada perubahan kecil dalam rutinitas sehari-hari di kafe yang sering ia kunjungi. Rudi juga cenderung menanggapi kebutuhan orang lain tanpa diminta, seperti membantu tetangga membawa belanjaan atau memberi tempat duduk kepada seorang ibu hamil di bus. Dengan kepribadiannya yang penuh perhatian terhadap sekitarnya, Rudi menjalin hubungan yang kuat dengan komunitasnya dan selalu memberikan sentuhan manusiawi pada setiap momen sehari-hari.\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-03T03:17:33.280552Z",
          "iopub.execute_input": "2023-12-03T03:17:33.280848Z",
          "iopub.status.idle": "2023-12-03T03:17:34.088713Z",
          "shell.execute_reply.started": "2023-12-03T03:17:33.280821Z",
          "shell.execute_reply": "2023-12-03T03:17:34.087883Z"
        },
        "trusted": true,
        "id": "hXV_TEJ5wpjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df075b26-d52c-4a0b-9977-1ddd39f5f7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9440896]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# intuitive == 0\n",
        "model.predict([\"memiliki kecenderungan untuk fokus pada ide-ide besar, potensi, dan konsep-konsep abstrak. Mereka melihat gambaran keseluruhan dan mencari makna di balik informasi yang mereka terima. Orang dengan preferensi intuisi dalam tipe kepribadian Myers-Briggs mungkin cenderung lebih suka berpikir tentang masa depan dan memiliki kepekaan terhadap peluang dan kemungkinan. Mereka sering menunjukkan kreativitas, daya khayal yang tinggi, dan ketertarikan pada ide-ide inovatif\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-03T03:19:32.484897Z",
          "iopub.execute_input": "2023-12-03T03:19:32.485717Z",
          "iopub.status.idle": "2023-12-03T03:19:32.573925Z",
          "shell.execute_reply.started": "2023-12-03T03:19:32.485680Z",
          "shell.execute_reply": "2023-12-03T03:19:32.573211Z"
        },
        "trusted": true,
        "id": "NkjO27duwpjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f90020-1be1-4c43-bf66-64d6cd4714a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04995943]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh: Memuat model SavedModel\n",
        "loaded_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/model_sn\")\n",
        "\n",
        "# Sekarang, Anda dapat menggunakan loaded_model seperti model lainnya\n",
        "# Misalnya: melakukan prediksi\n",
        "\n",
        "predictions = loaded_model.predict([\"senang menyimak keadaan sekitarnya dengan seksama. Setiap hari, ia akan memperhatikan hal-hal kecil yang mungkin terlewatkan oleh orang lain. Misalnya, ia selalu tahu kapan tetangganya mengganti bunga di halaman depan rumahnya atau ketika ada perubahan kecil dalam rutinitas sehari-hari di kafe yang sering ia kunjungi. Rudi juga cenderung menanggapi kebutuhan orang lain tanpa diminta, seperti membantu tetangga membawa belanjaan atau memberi tempat duduk kepada seorang ibu hamil di bus. Dengan kepribadiannya yang penuh perhatian terhadap sekitarnya, Rudi menjalin hubungan yang kuat dengan komunitasnya dan selalu memberikan sentuhan manusiawi pada setiap momen sehari-hari.\"])\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdCgoT1fRyaf",
        "outputId": "a32eb3c5-2225-480c-94f4-9b5aa4983ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[0.9440896]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan daftar perangkat yang tersedia (CPU dan GPU)\n",
        "devices = tf.config.list_physical_devices()\n",
        "\n",
        "if len(devices) == 0:\n",
        "    print(\"Tidak ada perangkat fisik yang ditemukan.\")\n",
        "else:\n",
        "    print(\"Perangkat yang tersedia:\")\n",
        "    for device in devices:\n",
        "        print(f\"- {device.name} ({device.device_type})\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-03T03:17:34.248899Z",
          "iopub.status.idle": "2023-12-03T03:17:34.249409Z",
          "shell.execute_reply.started": "2023-12-03T03:17:34.249139Z",
          "shell.execute_reply": "2023-12-03T03:17:34.249164Z"
        },
        "trusted": true,
        "id": "JFlrCckGwpju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([\"sayap pergi sangat mudah temukan berhubungan setiap enneagram infj langka mustahil tidak mungkin semuanya mungkin tergantung naikkan cuure dll menang temukan banyak enneagram individualis di korea utara contoh mungkin kamp konsentrasi mh tebak akan membantu akan menemukan dosa mematikan lihat masalah lol iri sangat jelas tidak puas salah satu favorit katakan agak suka menyalin mekanisme seperti tidak ada hal semuanya akan baik-baik saja mungkin berpengaruh dengan baik semoga memperbaiki kerakusan di bawah kendali kecuali menggoda rumah coklat makan semuanya suatu hari gulma merokok tidak ada yang meninggalkan orang yang terlalu marah berarti kencing lelucon inti mempengaruhi banyak prolly w bermain dengan baik seseorang sesuatu yang terbelakang cara perlahan-lahan membuat gila seperti tahu seperti hei mengemudi kayu tengah tidak ada tempat duduk biarkan mengambil roda mobil duduk menang dapat mengemudi lagi hei paling tidak bisa duduk hahahahah ieriozuepoanhceiphfiozejfijrioe berhenti contoh buruk cukup mudah-mudahan memperbaiki fokus pikiran yang sadar akan sangat membantu dengan baik mungkin membutuhkan waktu pada akhirnya menjadi jelas kirim sesuatu mungkin perlu perubahan tahu partikal diskrit berpikir sebagian besar berpikir cara terhitung banyaknya bayangkan paling tidak mendekati sesuatu yang diskrit bahkan seperti fungsi tidak pernah cukup konvergen masalah fungsi kontinu topps mengurutkan basis deteksi emulasi menggunakan perangkat lunak tertentu menggunakan tujuan perangkat lunak bahkan meniru akan memicu perma larangan membeli paket skema baru-baru ini berharap satu opsi izinkan giliran animasi ingin mengenai paket kartu tambahkan stok perlu melihat paket terbuka pasti ingin melihat sumber daya jelek hit ringan terjadi kartu pertama oleh karena itu tutup waktu paket berhenti buka paket paling tidak akan cepat secara teoritis topps dapat memperkenalkan opsi pembelian mui akan sangat buruk aplikasi setidaknya tombol pembelian paket manual lambat pembeli besar pembeli kecil dapatkan paket populer jika tidak, paus dapat sepenuhnya membeli kartu satu pembelian tahu benar berani orang berpikir percaya hal mengatakan dunia pukulan tongkat mengapung selamanya ruang membekukan bola mati lemas mampu membuat kesepakatan kesengsaraan dua secara profesional mengakhiri kebencian cocok stereotip buruk keras suka memerintah kaku tak kenal ampun menurunkan semangat menjengkelkan satu mitra bisnis bertarung dengan keras secara agresif menunggu satu sama lain departemen pekerjaan yang berbeda mempengaruhi pekerjaan orang menjengkelkan yang menyedihkan membuat semua orang di sekitar menderita harapan bertemu dengan contoh yang baik sosiopat masa depan imo mengatakan dengan tepat satu akan mengatakan edit oh terima kasih Tuhan semua orang mendapatkan keramahan yang rendah jujur ?de?????de????menang mudah intj entj fungsi urutan yang berbeda intjs seperti banyak introvert sering memimpin fungsi tambahan situasi sosial perbedaan besar entjs kebutuhan tinggi menyelesaikan hal intjs kebutuhan tinggi secara akurat memahami intjs datang menggigit lalai ni biarkan kepala hidup gunakan te secara proaktif menjaga lebih memilih dukungan lingkungan ni mampu menjaga tatanan lingkungan ideal dengan benar mengarahkan energi ke dalam entj gunakan ni melayani te gunakan refleksi prediksi memesan tujuan satu cara mungkin membedakan reaksi gangguan lingkungan intj menjengkelkan seperti perbaikan hebat mendapatkan kembali hal yang sangat peduli entj oportunistik berpikir peluang besar mengatur ulang cara pasti enfps cinta istjs baik gender teman enfps kreativitas semangat hidup menemukan sangat menarik sensitivitas bebas semangat keseimbangan dingin kekakuan tambahan fi tersier te temukan di antara orang-orang yang sangat memahami nilai pandangan dunia bahkan setuju meskipun istjs berbagi fungsi sering menemukan tangkapan membatasi si konotasi teman monster monster berpikir pengungkapan penuh entj bisnis pesanan biasa yaitu menginjak-injak menggambarkan monster seperti romantisisasi yang tidak perlu sama sekali sarung pedang dll melayani gangguan mungkin mengambil fakta berhenti memberi tahu op monster\"]))"
      ],
      "metadata": {
        "id": "qtk4dkOptsxD",
        "execution": {
          "iopub.status.busy": "2023-12-03T03:17:34.251456Z",
          "iopub.status.idle": "2023-12-03T03:17:34.251817Z",
          "shell.execute_reply.started": "2023-12-03T03:17:34.251648Z",
          "shell.execute_reply": "2023-12-03T03:17:34.251666Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path folder yang ingin di-zip\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/model_sensing_intuitive'\n",
        "\n",
        "# Path hasil zip\n",
        "output_zip_path = '/content/drive/MyDrive/Colab Notebooks/model_sn.zip'\n",
        "\n",
        "# Fungsi untuk zip folder\n",
        "def zip_folder(folder_path, output_zip_path):\n",
        "    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_path))\n",
        "\n",
        "# Memanggil fungsi untuk zip folder\n",
        "zip_folder(folder_path, output_zip_path)"
      ],
      "metadata": {
        "id": "o7C4lZoWDtaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}